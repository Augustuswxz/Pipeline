from langchain_core.messages import AIMessage, ToolMessage, SystemMessage
# from Tools.KBManager import view_knowledge_base, update_knowledge_base, delete_knowledge_base, add_new_standard_field, delete_standard_field_tool
from LLM.LLM import llm
from node_wrapper import node_wrapper
from Tools.tools_config import kb_tools
import json

llm_with_tools = llm.bind_tools(kb_tools)


@node_wrapper
def node_kb_management(state):
    print("=== âš™ï¸ è¿›å…¥çŸ¥è¯†åº“ç®¡ç†èŠ‚ç‚¹ ===")
    messages = state["messages"]
    memory = state.get("memory", {})

    if messages and isinstance(messages[-1], ToolMessage):
        last_msg = messages[-1]
        
        # åˆ¤æ–­æ˜¯å¦æ˜¯æŸ¥çœ‹çŸ¥è¯†åº“çš„å·¥å…·è¿”å›
        if last_msg.name == "view_knowledge_base":
            print("âš¡ï¸ æ£€æµ‹åˆ°åˆšæ‰§è¡Œå®ŒæŸ¥çœ‹çŸ¥è¯†åº“ï¼Œè·³è¿‡ LLMï¼Œç›´æ¥æ ¼å¼åŒ–è¾“å‡ºç»“æœã€‚")
            
            try:
                # 1. å°†å­—ç¬¦ä¸²ååºåˆ—åŒ–ä¸º Python åˆ—è¡¨
                kb_data = json.loads(last_msg.content)
                
                # 2. æ ¼å¼åŒ–é€»è¾‘ï¼šéå†åˆ—è¡¨ï¼Œæ‹¼æ¥å­—ç¬¦ä¸²
                # å‡è®¾æ•°æ®ç»“æ„æ˜¯: [{"standard": "A", "aliases": ["a1", "a2"]}, ...]
                formatted_lines = []
                
                # å®¹é”™ï¼šå¦‚æœè¿”å›çš„æ˜¯å•ä¸ªå­—å…¸ï¼Œè½¬ä¸ºåˆ—è¡¨
                if isinstance(kb_data, dict):
                    kb_data = [kb_data]
                    
                for item in kb_data:
                    standard = item.get("standard", "æœªçŸ¥å­—æ®µ")
                    aliases = item.get("aliases", [])
                    
                    # å°†åˆ«ååˆ—è¡¨è½¬ä¸ºå­—ç¬¦ä¸² (å¦‚æœæœ‰å¤šä¸ªåˆ«åï¼Œç”¨é€—å·åˆ†éš”)
                    if isinstance(aliases, list):
                        alias_str = ", ".join(aliases)
                    else:
                        alias_str = str(aliases)
                    
                    # æŒ‰ç…§ä½ çš„è¦æ±‚æ‹¼æ¥ï¼š Standardï¼šAlias
                    formatted_lines.append(f"{standard}ï¼š{alias_str}")
                
                # 3. ç»„åˆæœ€ç»ˆæ–‡æœ¬
                result_text = "\n".join(formatted_lines)
                final_content = f"**å½“å‰çŸ¥è¯†åº“æ˜ å°„è§„åˆ™å¦‚ä¸‹ï¼š**\n\n```text\n{result_text}\n```"

            except Exception as e:
                # å¦‚æœè§£æå¤±è´¥ï¼ˆæ¯”å¦‚è¿”å›çš„ä¸æ˜¯JSONï¼‰ï¼Œé™çº§ä¸ºç›´æ¥æ˜¾ç¤ºåŸå§‹å†…å®¹
                print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                final_content = f"**çŸ¥è¯†åº“å†…å®¹:**\n{last_msg.content}"

            # ç›´æ¥è¿”å›æ„é€ å¥½çš„ AIMessage
            return {
                "messages": [AIMessage(content=final_content)],
                "memory": memory
            }

    # 1. è°ƒç”¨ LLM
    response = llm_with_tools.invoke(messages)
    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    if response.tool_calls:
        print("ğŸ” æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨è¯·æ±‚ï¼š")
        for tool in response.tool_calls:
            tool_name = tool.get("name")
            tool_args = tool.get("args")
            print(f"   ğŸ› ï¸  å·¥å…·åç§°: {tool_name}")
            print(f"   ğŸ“‹  å‚æ•°å†…å®¹: {tool_args}")
    else:
        print("ğŸ—£ï¸  æ™ºèƒ½ä½“æœªè°ƒç”¨å·¥å…·ï¼Œç”Ÿæˆäº†æ™®é€šå›å¤ã€‚")
        
    return {
        "messages": [response],
        "memory": memory
    }
