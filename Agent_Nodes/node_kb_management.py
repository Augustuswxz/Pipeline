from langchain_core.messages import AIMessage, ToolMessage, SystemMessage
# from Tools.KBManager import view_knowledge_base, update_knowledge_base, delete_knowledge_base, add_new_standard_field, delete_standard_field_tool
from LLM.LLM import llm
from node_wrapper import node_wrapper
from Tools.tools_config import kb_tools

llm_with_tools = llm.bind_tools(kb_tools)


@node_wrapper
def node_kb_management(state):
    print("=== âš™ï¸ è¿›å…¥çŸ¥è¯†åº“ç®¡ç†èŠ‚ç‚¹ ===")
    messages = state["messages"]
    memory = state.get("memory", {})

    if messages and isinstance(messages[-1], ToolMessage):
        last_msg = messages[-1]
        # print("last_msg:", last_msg)
        if last_msg.name == "view_knowledge_base":
            print("âš¡ï¸ æ£€æµ‹åˆ°åˆšæ‰§è¡Œå®ŒæŸ¥çœ‹çŸ¥è¯†åº“ï¼Œè·³è¿‡ LLM å¤„ç†ï¼Œç›´æ¥è¾“å‡ºç»“æœã€‚")
            
            # ç›´æ¥å°†å·¥å…·çš„è¾“å‡ºåŒ…è£…æˆ AI çš„å›å¤
            # ä¸ºäº†ç¾è§‚ï¼Œå¯ä»¥åŠ ä¸ª Markdown çš„ json åŒ…è£¹ï¼ˆå¦‚æœä¸åŠ ï¼Œå°±æ˜¯çº¯æ–‡æœ¬ï¼‰
            tool_output = last_msg.content
            formatted_content = f"**å½“å‰çŸ¥è¯†åº“å®Œæ•´å†…å®¹å¦‚ä¸‹ï¼š**\n\n```json\n{tool_output}\n```"
            
            return {
                "messages": [AIMessage(content=formatted_content)],
                "memory": memory
            }

    # 1. è°ƒç”¨ LLM
    response = llm_with_tools.invoke(messages)
    # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
    if response.tool_calls:
        print("ğŸ” æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨è¯·æ±‚ï¼š")
        for tool in response.tool_calls:
            tool_name = tool.get("name")
            tool_args = tool.get("args")
            print(f"   ğŸ› ï¸  å·¥å…·åç§°: {tool_name}")
            print(f"   ğŸ“‹  å‚æ•°å†…å®¹: {tool_args}")
    else:
        print("ğŸ—£ï¸  æ™ºèƒ½ä½“æœªè°ƒç”¨å·¥å…·ï¼Œç”Ÿæˆäº†æ™®é€šå›å¤ã€‚")
        
    return {
        "messages": [response],
        "memory": memory
    }
