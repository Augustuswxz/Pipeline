from langgraph.graph import StateGraph, END
from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage

from agent_state import AgentState
from LLM.LLM import llm
from Tools.intention_analysis import router_chain
from Tools.tools_config import kb_tools
from Agent_Nodes.llm_node import llm_node
from Agent_Nodes.node_data_cleaning import node_data_cleaning
# from Agent_Nodes.node_data_alignment import node_data_alignment
from Agent_Nodes.node_align_process import node_align_process
from Agent_Nodes.node_align_ask_user import node_align_ask_user
from Agent_Nodes.node_align_save import node_align_save
from Agent_Nodes.node_kb_management import node_kb_management
from langgraph.prebuilt import ToolNode, tools_condition

from typing import List
from typing_extensions import TypedDict

from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.checkpoint.memory import MemorySaver
import sqlite3 # ç¡®ä¿å¯¼å…¥äº† sqlite3

from node_wrapper import node_wrapper

def route_logic(state: AgentState):
    print("=== AI Semantic Router (æ™ºèƒ½è·¯ç”±) ===")

    # 1. è·å–ç”¨æˆ·æœ€æ–°æ¶ˆæ¯
    last_msg = state["messages"][-1]
    content = last_msg.content

    # === ã€æ–°å¢ä¿®å¤ã€‘ ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦å¤„äºâ€œç­‰å¾…é€‰æ‹©â€çŠ¶æ€ ===
    # å¦‚æœå†…å­˜ä¸­å·²ç»æ ‡è®°æ‰¾åˆ°äº†åŒ¹é… (align_match_found)ï¼Œä¸”ç”¨æˆ·è¾“å…¥äº† A æˆ– B
    # content = last_msg.content.strip().upper() # è½¬å¤§å†™ï¼Œæ–¹ä¾¿åŒ¹é… A/B
    # if state.get("align_match_found", True) and content in ["A", "B"]:
    #     print(f"User Input: {content} (æ•æ‰åˆ°é€‰é¡¹é€‰æ‹©)")
    #     print("Intent Decision: node_align_save")
    #     return "node_align_save" # ç›´æ¥è·³è½¬åˆ°ä¿å­˜èŠ‚ç‚¹

    # 2. è°ƒç”¨ LLM è¿›è¡Œæ„å›¾åˆ¤æ–­
    # router_chain ä¼šè¿”å›ä¸€ä¸ª RouteIntent å¯¹è±¡
    try:
        decision = router_chain.invoke({"question": content})
        next_node = decision.next_node
    except Exception as e:
        print(f"è·¯ç”±åˆ¤æ–­å‡ºé”™: {e}ï¼Œå›é€€åˆ°æ™®é€šå¯¹è¯")
        next_node = "node_general_llm"

    print(f"User Input: {content}")
    print(f"Intent Decision: {next_node}")

    # 3. è¿”å›å†³ç­–ç»“æœ (å­—ç¬¦ä¸²)
    # è¿™ä¸ªå­—ç¬¦ä¸²å¿…é¡»ä¸ graph.add_conditional_edges ä¸­çš„ key å¯¹åº”
    return next_node

def route_after_process(state):
    """process èŠ‚ç‚¹åçš„è·¯ç”±é€»è¾‘"""
    if state["align_match_found"]:
        return "node_align_ask_user"  # æœ‰åŒ¹é… -> å»æé—®
    else:
        return "node_align_save"      # æ— åŒ¹é… -> ç›´æ¥å»ä¿å­˜

# ç©ºèŠ‚ç‚¹ä½œä¸ºå…¥å£
def router_entry_node(state: AgentState):
    pass


# ========== 7. æ„å»º Graph ==========
def build_graph():

    graph = StateGraph(AgentState)

    # æ³¨å†ŒèŠ‚ç‚¹
    graph.add_node("llm", node_wrapper(llm_node))
    graph.add_node("router", router_entry_node)
    # â˜…â˜…â˜… æ³¨å†Œæ–°èŠ‚ç‚¹ (æ³¨æ„åå­—è¦å¯¹åº”è·¯ç”±è¡¨ä¸­çš„ Value) â˜…â˜…â˜…
    graph.add_node("data_clean", node_wrapper(node_data_cleaning))      
    # å¯¹åº” "node_data_cleaning": "data_clean"
    # graph.add_node("data_alignment", node_wrapper(node_data_alignment))
    # å¯¹åº” "node_data_alignment": "data_alignment"
    graph.add_node("kb_management", node_kb_management)
    # çŸ¥è¯†åº“ç®¡ç†å·¥å…·
    kb_tool_node = ToolNode(kb_tools)
    graph.add_node("kb_tool_executor", kb_tool_node)
    # æ•°æ®å¯¹é½ç›¸å…³èŠ‚ç‚¹
    graph.add_node("process", node_align_process)
    graph.add_node("ask_user", node_align_ask_user)
    graph.add_node("save", node_align_save)

    # å…¥å£èŠ‚ç‚¹
    graph.set_entry_point("router")

    # æ¡ä»¶è·¯ç”±
    graph.add_conditional_edges(
        "router",
        route_logic,
        {
            "node_general_llm": "llm",
            "node_data_cleaning": "data_clean",
            "node_data_alignment": "process",
            "node_kb_management": "kb_management",
            # === ã€æ–°å¢æ˜ å°„ã€‘ å…è®¸ Router ç›´æ¥è·³åˆ° Save ===
            # "node_align_save": "save"
        },
    )

    graph.add_conditional_edges(
        "kb_management", 
        tools_condition, 
        {
            "tools": "kb_tool_executor",  # å¦‚æœè¦æ‰§è¡Œå·¥å…·ï¼Œå»æ‰§è¡ŒèŠ‚ç‚¹
            "__end__": END # å¦‚æœåªæ˜¯é—²èŠï¼Œå»é€šç”¨ LLM å›å¤
        }
    )

    # 1. Process ä¹‹åçš„æ¡ä»¶åˆ†æ”¯
    graph.add_conditional_edges(
        "process",
        route_after_process,
        {
            "node_align_ask_user": "ask_user",
            "node_align_save": "save"
        }
    )

    graph.add_edge("llm", END)
    graph.add_edge("data_clean", END)
    # graph.add_edge("data_alignment", END)
    graph.add_edge("kb_tool_executor", "kb_management")
    graph.add_edge("ask_user", "save")
    graph.add_edge("save", END)

    print("=== Graph æ„å»ºå®Œæˆ ===")

    # â˜…â˜…â˜…â˜…â˜… æ ¸å¿ƒï¼šæŒä¹…åŒ–è®°å¿†ï¼ˆSQLiteï¼‰
    conn = sqlite3.connect("agent_memory.db", check_same_thread=False)
    checkpointer = SqliteSaver(conn)
    # çŸ­æœŸè®°å¿†
    # checkpointer = MemorySaver() 

    return graph.compile(interrupt_after=["ask_user"], checkpointer=checkpointer)

# ========== 8. äº¤äº’å¼æµ‹è¯•ä»£ç  ==========
if __name__ == "__main__":
    graph = build_graph()

    with open("graph.png", "wb") as f:
        f.write(graph.get_graph().draw_mermaid_png())

    # å®šä¹‰ä¸€ä¸ªå›ºå®šçš„ thread_id
    # åªè¦è¿™ä¸ª ID ä¸å˜ï¼ŒAgent å°±ä¼šä» sqlite æ–‡ä»¶è¯»å–å†å²
    thread_id = "user_test_001"
    config = {"configurable": {"thread_id": thread_id}}

    print(f"ğŸš€ å¯åŠ¨ Agent (Thread ID: {thread_id})")
    print("ğŸ’¾ è®°å¿†å°†ä¼šä¿å­˜åœ¨ 'agent_memory.db' æ–‡ä»¶ä¸­")
    print("ğŸ’¡ è¾“å…¥ 'exit' æˆ– 'q' é€€å‡ºç¨‹åº")
    print("-" * 50)

    while True:
        user_input = input("\nğŸ‘¤ User: ").strip()
        if user_input.lower() in ["exit", "quit", "q"]:
            print("ğŸ‘‹ å†è§ï¼")
            break
        
        if not user_input:
            continue

        # æ„é€ è¾“å…¥çŠ¶æ€
        # æ³¨æ„ï¼šå› ä¸ºä½ æ²¡æœ‰ä½¿ç”¨ add_messages reducerï¼ŒLangGraph é»˜è®¤è¡Œä¸ºé€šå¸¸æ˜¯æ›¿æ¢ã€‚
        # ä½†æ˜¯ SqliteSaver ä¼šåŠ è½½ä¹‹å‰çš„ checkpointã€‚
        # ä¸ºäº†ç¨³å¦¥ï¼Œæˆ‘ä»¬è¿™é‡Œä¼ å•ä¸ªæ¶ˆæ¯ï¼ŒLangGraph ä¼šåœ¨å†…éƒ¨åˆå¹¶ Stateã€‚
        # inputs = {"messages": [HumanMessage(content=user_input)]}

        # === ä¿®æ”¹æ ¸å¿ƒé€»è¾‘å¼€å§‹ ===
        
        # 1. è·å–å½“å‰çŠ¶æ€å¿«ç…§
        snapshot = graph.get_state(config)

        # 2. æ£€æŸ¥æ˜¯å¦æœ‰æš‚åœçš„ä»»åŠ¡ (next ä¸ä¸ºç©ºè¯´æ˜åœåœ¨æŸä¸ªèŠ‚ç‚¹ä¹‹å)
        if snapshot.next:
            print("   (æ£€æµ‹åˆ°å¹¶åœ¨ä¸­é€”ä¸­æ–­ï¼Œæ­£åœ¨æ¢å¤...)")
            
            # 2.1 å°†ç”¨æˆ·çš„å›ç­” ("A" æˆ– "B") æ›´æ–°åˆ° Messages å†å²ä¸­
            # è¿™æ · 'save' èŠ‚ç‚¹å°±èƒ½è¯»åˆ°ç”¨æˆ·çš„é€‰æ‹©
            graph.update_state(
                config, 
                {"messages": [HumanMessage(content=user_input)]},
                as_node="ask_user"  # <--- åŠ ä¸Šè¿™ä¸€å¥ï¼
            )
            
            # 2.2 ç»§ç»­è¿è¡Œ (ä¼ å…¥ None è¡¨ç¤ºä¸ä»å¤´å¼€å§‹ï¼Œè€Œæ˜¯ä»æ–­ç‚¹ç»§ç»­)
            # æ­¤æ—¶ä¼šæ²¿ç€ ask_user -> save çš„è¾¹ç»§ç»­èµ°
            events = graph.stream(None, config=config)
        else:
            # 3. å¦‚æœæ²¡æœ‰æš‚åœï¼Œåˆ™è§†ä¸ºæ–°çš„å¯¹è¯ï¼Œä» Entry Point (Router) å¼€å§‹
            inputs = {"messages": [HumanMessage(content=user_input)]}
            events = graph.stream(inputs, config=config)

        try:
            # ä½¿ç”¨ stream è¿™æ ·å¯ä»¥çœ‹åˆ°ä¸­é—´è¿‡ç¨‹ï¼ˆæ¯”å¦‚è¿›å…¥äº†å“ªä¸ªèŠ‚ç‚¹ï¼‰
            # print("   (å¤„ç†ä¸­...)") 
            final_state = None
            
            # for event in graph.stream(inputs, config=config):
            for event in events:
                for node_name, value in event.items():
                    # print(f"   -> ç»è¿‡èŠ‚ç‚¹: {node_name}")
                    final_state = value
            
            if final_state:
                # æå–æœ€åä¸€æ¡æ¶ˆæ¯
                last_msg = final_state["messages"][-1]
                print(f"ğŸ¤– AI: {last_msg.content}")
                
                # ğŸ” æ˜¾ç¤ºå½“å‰çš„æ˜¾å¼è®°å¿† (Debugç”¨é€”)
                current_memory = final_state.get("memory", {})
                if current_memory:
                    print(f"   [å½“å‰è„‘ä¸­è®°å¿†]: {current_memory}")
            
        except Exception as e:
            print(f"ğŸ’¥ å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()